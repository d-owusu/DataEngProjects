This big data project will look at Hive's capabilities to run analytical queries on massive
datasets. We will use the Adventure works dataset in a MySQL dataset for this project,
and we'll need to ingest and modify the data.


-Create an AWS EC2 instance and launch it.
-Create docker images using docker-compose file on EC2 machine via ssh.
-Create tables in MySQL.
-Load data from MySQL into HDFS storage using Sqoop commands.
-Move data from HDFS to Hive.
-Integrate Hive into Spark.
- Using scala programming language, extract Customer demographics information
from data and store it as parquet files.
-Move parquet files from Spark to Hive.
-Create tables in Hive and load data from Parquet files into tables.
-Perform Hive analytics on Sales and Customer demographics data.
